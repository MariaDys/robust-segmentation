{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "SndLW5kN00Yw"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariaDys/robust-segmentation/blob/main/robust_segmentation_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKcbVlPG9H1M",
        "outputId": "be3fda52-c5a2-4ca9-8ef9-b49095e35fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'robust-segmentation'...\n",
            "remote: Enumerating objects: 1056, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 1056 (delta 90), reused 48 (delta 48), pack-reused 952\u001b[K\n",
            "Receiving objects: 100% (1056/1056), 91.67 MiB | 15.93 MiB/s, done.\n",
            "Resolving deltas: 100% (726/726), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nmndeep/robust-segmentation.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PGFo-FWaaXR",
        "outputId": "048888e7-a390-4d82-8d23-2f892b345567"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"hhttps://groups.csail.mit.edu/vision/datasets/ADE20K/syml/madyskina_7bde9149.zip\"\n",
        "r = requests.get(url)\n",
        "\n",
        "with open(\"madyskina_7bde9149.zip\", \"wb\") as f:\n",
        "    f.write(r.content)"
      ],
      "metadata": {
        "id": "eGSr6q6WkSHU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown"
      ],
      "metadata": {
        "id": "fcACJJraoEgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f165a8f0-7194-4258-b845-6426edab58a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "url = 'https://groups.csail.mit.edu/vision/datasets/ADE20K/syml/madyskina_7bde9149.zip'\n",
        "output = '/content/drive/My Drive/madyskina_7bde9149.zip'  # Путь на вашем Google Диске\n",
        "\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "id": "Tm4NHl6ZH2d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "23a6c1d1-9906-4368-af34-110c1e924c93"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://groups.csail.mit.edu/vision/datasets/ADE20K/syml/madyskina_7bde9149.zip\n",
            "To: /content/drive/My Drive/madyskina_7bde9149.zip\n",
            "100%|██████████| 6.04G/6.04G [02:29<00:00, 40.4MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/madyskina_7bde9149.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "zip_file_path = '/content/drive/My Drive/madyskina_7bde9149.zip'\n",
        "extract_to = '/content/ade20k'\n",
        "\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)"
      ],
      "metadata": {
        "id": "Rh0haqlmwnJR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "current_directory = os.getcwd()\n",
        "print(current_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjfhFbeFx1aZ",
        "outputId": "8fa132d9-ede8-42d5-c2ce-4855f78bd9d9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-LM3fT6ypO7",
        "outputId": "00b055db-9de7-412a-e845-b0d36c55cb1e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.17.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->timm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->timm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->timm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->timm)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->timm)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->timm)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->timm)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->timm)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->timm)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->timm)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->timm)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 timm-0.9.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1Oy_xqX1n4O",
        "outputId": "6950b94d-74ff-44e6-ef0b-3acec5ac6f53"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/fra31/auto-attack.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFdwrxyr11qH",
        "outputId": "870ec313-08e2-4a52-ef21-23e1df6469f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/fra31/auto-attack.git\n",
            "  Cloning https://github.com/fra31/auto-attack.git to /tmp/pip-req-build-rrstut8v\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/fra31/auto-attack.git /tmp/pip-req-build-rrstut8v\n",
            "  Resolved https://github.com/fra31/auto-attack.git to commit a39220048b3c9f2cca9a4d3a54604793c68eca7e\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: autoattack\n",
            "  Building wheel for autoattack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autoattack: filename=autoattack-0.1-py3-none-any.whl size=36229 sha256=b0dbbcc0f83ee43fe070dc03b8418112fb2b666dadd0f7beb20cf2175ddcf1b4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cnbff__5/wheels/95/9e/34/c5d97e00c1e2f0f685c3c4000a35217b58f75e0f442db962c1\n",
            "Successfully built autoattack\n",
            "Installing collected packages: autoattack\n",
            "Successfully installed autoattack-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fvcore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ_bLfUq2Dom",
        "outputId": "25de898c-9253-42d6-dd89-3877e1087e30"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore) (1.25.2)\n",
            "Collecting yacs>=0.1.6 (from fvcore)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (6.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore) (4.66.2)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore) (2.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore) (9.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore) (0.9.0)\n",
            "Collecting iopath>=0.1.7 (from fvcore)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath>=0.1.7->fvcore) (4.10.0)\n",
            "Collecting portalocker (from iopath>=0.1.7->fvcore)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=9e81d0c77fd08f23b73607343e1573900c7bc8201fc01d9ea56fa0b6ab5f3808\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=ec2e23f23fd810743aebcf595cf9f2611e9832379eee6b4e288b13b193e3f271\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-2.8.2 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #Веса\n",
        "# import shutil\n",
        "# file_to_move = '/checkpoint.pth'\n",
        "# destination_folder = '/content'\n",
        "# shutil.move(file_to_move, destination_folder)"
      ],
      "metadata": {
        "id": "8kox2fcC307_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SegFormer"
      ],
      "metadata": {
        "id": "SndLW5kN00Yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "processor = SegformerImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
        "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmS_HPEs0uHk",
        "outputId": "61a4f8d1-523a-4697-a34b-7dc5231df7f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/segformer/image_processing_segformer.py:102: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save_pretrained(\"/content/robust-segmentation/model\")\n",
        "\n",
        "import torch\n",
        "\n",
        "torch.save(model.state_dict(), \"/content/robust-segmentation/model/model.pth\")"
      ],
      "metadata": {
        "id": "_2MxM9Ex0sAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in model.state_dict().keys():\n",
        "    print(key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZRNKqxrU7KL",
        "outputId": "cf9b5fc8-1d80-4b0a-cde4-833d68f6c13f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "segformer.encoder.patch_embeddings.0.proj.weight\n",
            "segformer.encoder.patch_embeddings.0.proj.bias\n",
            "segformer.encoder.patch_embeddings.0.layer_norm.weight\n",
            "segformer.encoder.patch_embeddings.0.layer_norm.bias\n",
            "segformer.encoder.patch_embeddings.1.proj.weight\n",
            "segformer.encoder.patch_embeddings.1.proj.bias\n",
            "segformer.encoder.patch_embeddings.1.layer_norm.weight\n",
            "segformer.encoder.patch_embeddings.1.layer_norm.bias\n",
            "segformer.encoder.patch_embeddings.2.proj.weight\n",
            "segformer.encoder.patch_embeddings.2.proj.bias\n",
            "segformer.encoder.patch_embeddings.2.layer_norm.weight\n",
            "segformer.encoder.patch_embeddings.2.layer_norm.bias\n",
            "segformer.encoder.patch_embeddings.3.proj.weight\n",
            "segformer.encoder.patch_embeddings.3.proj.bias\n",
            "segformer.encoder.patch_embeddings.3.layer_norm.weight\n",
            "segformer.encoder.patch_embeddings.3.layer_norm.bias\n",
            "segformer.encoder.block.0.0.layer_norm_1.weight\n",
            "segformer.encoder.block.0.0.layer_norm_1.bias\n",
            "segformer.encoder.block.0.0.attention.self.query.weight\n",
            "segformer.encoder.block.0.0.attention.self.query.bias\n",
            "segformer.encoder.block.0.0.attention.self.key.weight\n",
            "segformer.encoder.block.0.0.attention.self.key.bias\n",
            "segformer.encoder.block.0.0.attention.self.value.weight\n",
            "segformer.encoder.block.0.0.attention.self.value.bias\n",
            "segformer.encoder.block.0.0.attention.self.sr.weight\n",
            "segformer.encoder.block.0.0.attention.self.sr.bias\n",
            "segformer.encoder.block.0.0.attention.self.layer_norm.weight\n",
            "segformer.encoder.block.0.0.attention.self.layer_norm.bias\n",
            "segformer.encoder.block.0.0.attention.output.dense.weight\n",
            "segformer.encoder.block.0.0.attention.output.dense.bias\n",
            "segformer.encoder.block.0.0.layer_norm_2.weight\n",
            "segformer.encoder.block.0.0.layer_norm_2.bias\n",
            "segformer.encoder.block.0.0.mlp.dense1.weight\n",
            "segformer.encoder.block.0.0.mlp.dense1.bias\n",
            "segformer.encoder.block.0.0.mlp.dwconv.dwconv.weight\n",
            "segformer.encoder.block.0.0.mlp.dwconv.dwconv.bias\n",
            "segformer.encoder.block.0.0.mlp.dense2.weight\n",
            "segformer.encoder.block.0.0.mlp.dense2.bias\n",
            "segformer.encoder.block.0.1.layer_norm_1.weight\n",
            "segformer.encoder.block.0.1.layer_norm_1.bias\n",
            "segformer.encoder.block.0.1.attention.self.query.weight\n",
            "segformer.encoder.block.0.1.attention.self.query.bias\n",
            "segformer.encoder.block.0.1.attention.self.key.weight\n",
            "segformer.encoder.block.0.1.attention.self.key.bias\n",
            "segformer.encoder.block.0.1.attention.self.value.weight\n",
            "segformer.encoder.block.0.1.attention.self.value.bias\n",
            "segformer.encoder.block.0.1.attention.self.sr.weight\n",
            "segformer.encoder.block.0.1.attention.self.sr.bias\n",
            "segformer.encoder.block.0.1.attention.self.layer_norm.weight\n",
            "segformer.encoder.block.0.1.attention.self.layer_norm.bias\n",
            "segformer.encoder.block.0.1.attention.output.dense.weight\n",
            "segformer.encoder.block.0.1.attention.output.dense.bias\n",
            "segformer.encoder.block.0.1.layer_norm_2.weight\n",
            "segformer.encoder.block.0.1.layer_norm_2.bias\n",
            "segformer.encoder.block.0.1.mlp.dense1.weight\n",
            "segformer.encoder.block.0.1.mlp.dense1.bias\n",
            "segformer.encoder.block.0.1.mlp.dwconv.dwconv.weight\n",
            "segformer.encoder.block.0.1.mlp.dwconv.dwconv.bias\n",
            "segformer.encoder.block.0.1.mlp.dense2.weight\n",
            "segformer.encoder.block.0.1.mlp.dense2.bias\n",
            "segformer.encoder.block.1.0.layer_norm_1.weight\n",
            "segformer.encoder.block.1.0.layer_norm_1.bias\n",
            "segformer.encoder.block.1.0.attention.self.query.weight\n",
            "segformer.encoder.block.1.0.attention.self.query.bias\n",
            "segformer.encoder.block.1.0.attention.self.key.weight\n",
            "segformer.encoder.block.1.0.attention.self.key.bias\n",
            "segformer.encoder.block.1.0.attention.self.value.weight\n",
            "segformer.encoder.block.1.0.attention.self.value.bias\n",
            "segformer.encoder.block.1.0.attention.self.sr.weight\n",
            "segformer.encoder.block.1.0.attention.self.sr.bias\n",
            "segformer.encoder.block.1.0.attention.self.layer_norm.weight\n",
            "segformer.encoder.block.1.0.attention.self.layer_norm.bias\n",
            "segformer.encoder.block.1.0.attention.output.dense.weight\n",
            "segformer.encoder.block.1.0.attention.output.dense.bias\n",
            "segformer.encoder.block.1.0.layer_norm_2.weight\n",
            "segformer.encoder.block.1.0.layer_norm_2.bias\n",
            "segformer.encoder.block.1.0.mlp.dense1.weight\n",
            "segformer.encoder.block.1.0.mlp.dense1.bias\n",
            "segformer.encoder.block.1.0.mlp.dwconv.dwconv.weight\n",
            "segformer.encoder.block.1.0.mlp.dwconv.dwconv.bias\n",
            "segformer.encoder.block.1.0.mlp.dense2.weight\n",
            "segformer.encoder.block.1.0.mlp.dense2.bias\n",
            "segformer.encoder.block.1.1.layer_norm_1.weight\n",
            "segformer.encoder.block.1.1.layer_norm_1.bias\n",
            "segformer.encoder.block.1.1.attention.self.query.weight\n",
            "segformer.encoder.block.1.1.attention.self.query.bias\n",
            "segformer.encoder.block.1.1.attention.self.key.weight\n",
            "segformer.encoder.block.1.1.attention.self.key.bias\n",
            "segformer.encoder.block.1.1.attention.self.value.weight\n",
            "segformer.encoder.block.1.1.attention.self.value.bias\n",
            "segformer.encoder.block.1.1.attention.self.sr.weight\n",
            "segformer.encoder.block.1.1.attention.self.sr.bias\n",
            "segformer.encoder.block.1.1.attention.self.layer_norm.weight\n",
            "segformer.encoder.block.1.1.attention.self.layer_norm.bias\n",
            "segformer.encoder.block.1.1.attention.output.dense.weight\n",
            "segformer.encoder.block.1.1.attention.output.dense.bias\n",
            "segformer.encoder.block.1.1.layer_norm_2.weight\n",
            "segformer.encoder.block.1.1.layer_norm_2.bias\n",
            "segformer.encoder.block.1.1.mlp.dense1.weight\n",
            "segformer.encoder.block.1.1.mlp.dense1.bias\n",
            "segformer.encoder.block.1.1.mlp.dwconv.dwconv.weight\n",
            "segformer.encoder.block.1.1.mlp.dwconv.dwconv.bias\n",
            "segformer.encoder.block.1.1.mlp.dense2.weight\n",
            "segformer.encoder.block.1.1.mlp.dense2.bias\n",
            "segformer.encoder.block.2.0.layer_norm_1.weight\n",
            "segformer.encoder.block.2.0.layer_norm_1.bias\n",
            "segformer.encoder.block.2.0.attention.self.query.weight\n",
            "segformer.encoder.block.2.0.attention.self.query.bias\n",
            "segformer.encoder.block.2.0.attention.self.key.weight\n",
            "segformer.encoder.block.2.0.attention.self.key.bias\n",
            "segformer.encoder.block.2.0.attention.self.value.weight\n",
            "segformer.encoder.block.2.0.attention.self.value.bias\n",
            "segformer.encoder.block.2.0.attention.self.sr.weight\n",
            "segformer.encoder.block.2.0.attention.self.sr.bias\n",
            "segformer.encoder.block.2.0.attention.self.layer_norm.weight\n",
            "segformer.encoder.block.2.0.attention.self.layer_norm.bias\n",
            "segformer.encoder.block.2.0.attention.output.dense.weight\n",
            "segformer.encoder.block.2.0.attention.output.dense.bias\n",
            "segformer.encoder.block.2.0.layer_norm_2.weight\n",
            "segformer.encoder.block.2.0.layer_norm_2.bias\n",
            "segformer.encoder.block.2.0.mlp.dense1.weight\n",
            "segformer.encoder.block.2.0.mlp.dense1.bias\n",
            "segformer.encoder.block.2.0.mlp.dwconv.dwconv.weight\n",
            "segformer.encoder.block.2.0.mlp.dwconv.dwconv.bias\n",
            "segformer.encoder.block.2.0.mlp.dense2.weight\n",
            "segformer.encoder.block.2.0.mlp.dense2.bias\n",
            "segformer.encoder.block.2.1.layer_norm_1.weight\n",
            "segformer.encoder.block.2.1.layer_norm_1.bias\n",
            "segformer.encoder.block.2.1.attention.self.query.weight\n",
            "segformer.encoder.block.2.1.attention.self.query.bias\n",
            "segformer.encoder.block.2.1.attention.self.key.weight\n",
            "segformer.encoder.block.2.1.attention.self.key.bias\n",
            "segformer.encoder.block.2.1.attention.self.value.weight\n",
            "segformer.encoder.block.2.1.attention.self.value.bias\n",
            "segformer.encoder.block.2.1.attention.self.sr.weight\n",
            "segformer.encoder.block.2.1.attention.self.sr.bias\n",
            "segformer.encoder.block.2.1.attention.self.layer_norm.weight\n",
            "segformer.encoder.block.2.1.attention.self.layer_norm.bias\n",
            "segformer.encoder.block.2.1.attention.output.dense.weight\n",
            "segformer.encoder.block.2.1.attention.output.dense.bias\n",
            "segformer.encoder.block.2.1.layer_norm_2.weight\n",
            "segformer.encoder.block.2.1.layer_norm_2.bias\n",
            "segformer.encoder.block.2.1.mlp.dense1.weight\n",
            "segformer.encoder.block.2.1.mlp.dense1.bias\n",
            "segformer.encoder.block.2.1.mlp.dwconv.dwconv.weight\n",
            "segformer.encoder.block.2.1.mlp.dwconv.dwconv.bias\n",
            "segformer.encoder.block.2.1.mlp.dense2.weight\n",
            "segformer.encoder.block.2.1.mlp.dense2.bias\n",
            "segformer.encoder.block.3.0.layer_norm_1.weight\n",
            "segformer.encoder.block.3.0.layer_norm_1.bias\n",
            "segformer.encoder.block.3.0.attention.self.query.weight\n",
            "segformer.encoder.block.3.0.attention.self.query.bias\n",
            "segformer.encoder.block.3.0.attention.self.key.weight\n",
            "segformer.encoder.block.3.0.attention.self.key.bias\n",
            "segformer.encoder.block.3.0.attention.self.value.weight\n",
            "segformer.encoder.block.3.0.attention.self.value.bias\n",
            "segformer.encoder.block.3.0.attention.output.dense.weight\n",
            "segformer.encoder.block.3.0.attention.output.dense.bias\n",
            "segformer.encoder.block.3.0.layer_norm_2.weight\n",
            "segformer.encoder.block.3.0.layer_norm_2.bias\n",
            "segformer.encoder.block.3.0.mlp.dense1.weight\n",
            "segformer.encoder.block.3.0.mlp.dense1.bias\n",
            "segformer.encoder.block.3.0.mlp.dwconv.dwconv.weight\n",
            "segformer.encoder.block.3.0.mlp.dwconv.dwconv.bias\n",
            "segformer.encoder.block.3.0.mlp.dense2.weight\n",
            "segformer.encoder.block.3.0.mlp.dense2.bias\n",
            "segformer.encoder.block.3.1.layer_norm_1.weight\n",
            "segformer.encoder.block.3.1.layer_norm_1.bias\n",
            "segformer.encoder.block.3.1.attention.self.query.weight\n",
            "segformer.encoder.block.3.1.attention.self.query.bias\n",
            "segformer.encoder.block.3.1.attention.self.key.weight\n",
            "segformer.encoder.block.3.1.attention.self.key.bias\n",
            "segformer.encoder.block.3.1.attention.self.value.weight\n",
            "segformer.encoder.block.3.1.attention.self.value.bias\n",
            "segformer.encoder.block.3.1.attention.output.dense.weight\n",
            "segformer.encoder.block.3.1.attention.output.dense.bias\n",
            "segformer.encoder.block.3.1.layer_norm_2.weight\n",
            "segformer.encoder.block.3.1.layer_norm_2.bias\n",
            "segformer.encoder.block.3.1.mlp.dense1.weight\n",
            "segformer.encoder.block.3.1.mlp.dense1.bias\n",
            "segformer.encoder.block.3.1.mlp.dwconv.dwconv.weight\n",
            "segformer.encoder.block.3.1.mlp.dwconv.dwconv.bias\n",
            "segformer.encoder.block.3.1.mlp.dense2.weight\n",
            "segformer.encoder.block.3.1.mlp.dense2.bias\n",
            "segformer.encoder.layer_norm.0.weight\n",
            "segformer.encoder.layer_norm.0.bias\n",
            "segformer.encoder.layer_norm.1.weight\n",
            "segformer.encoder.layer_norm.1.bias\n",
            "segformer.encoder.layer_norm.2.weight\n",
            "segformer.encoder.layer_norm.2.bias\n",
            "segformer.encoder.layer_norm.3.weight\n",
            "segformer.encoder.layer_norm.3.bias\n",
            "decode_head.linear_c.0.proj.weight\n",
            "decode_head.linear_c.0.proj.bias\n",
            "decode_head.linear_c.1.proj.weight\n",
            "decode_head.linear_c.1.proj.bias\n",
            "decode_head.linear_c.2.proj.weight\n",
            "decode_head.linear_c.2.proj.bias\n",
            "decode_head.linear_c.3.proj.weight\n",
            "decode_head.linear_c.3.proj.bias\n",
            "decode_head.linear_fuse.weight\n",
            "decode_head.batch_norm.weight\n",
            "decode_head.batch_norm.bias\n",
            "decode_head.batch_norm.running_mean\n",
            "decode_head.batch_norm.running_var\n",
            "decode_head.batch_norm.num_batches_tracked\n",
            "decode_head.classifier.weight\n",
            "decode_head.classifier.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 robust-segmentation/tools/infer.py --adversarial --cfg robust-segmentation/configs/ade20k_segmenter_clean.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQrkp-9UyNde",
        "outputId": "efc6f05a-e8ee-4148-d254-51d39eea3e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/content/robust-segmentation/tools/infer.py\", line 17\n",
            "    from\n",
            "        ^\n",
            "SyntaxError: invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#в файле /content/robust-segmentation/tools/semseg/models/segmenter.py  197 строчка (default_cfg)"
      ],
      "metadata": {
        "id": "bEZ3JqfnBdzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 755 /content/robust-segmentation/runner_infer.sh\n",
        "!/content/robust-segmentation/runner_infer.sh"
      ],
      "metadata": {
        "id": "7oXCHFyb5L8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee639d03-f6a2-41dd-9add-65cb12926cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/robust-segmentation/runner_infer.sh: line 11: scontrol: command not found\n",
            "python3: can't open file '/content/./tools/infer.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "processor = SegformerImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
        "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
        "\n",
        "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
        "image = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "inputs = processor(images=image, return_tensors=\"pt\")\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "mRFAbJn8XhWm",
        "outputId": "ae12bbe5-1859-44ad-972c-7fa0c8bfc65f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-de1ae2a83d91>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSegformerImageProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nvidia/segformer-b0-finetuned-ade-512-512\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSegformerForSemanticSegmentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nvidia/segformer-b0-finetuned-ade-512-512\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/image_processing_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mimage_processor_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_processor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_processor_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/image_processing_utils.py\u001b[0m in \u001b[0;36mget_image_processor_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 resolved_image_processor_file = cached_file(\n\u001b[0m\u001b[1;32m    335\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                     \u001b[0mimage_processor_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1238\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1239\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                     \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;31m# Recursively follow relative redirects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;31m# Perform request and return if status_code is not in the retry list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;34m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_AMZN_TRACE_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import SegformerForSemanticSegmentation\n",
        "model.save_pretrained(\"/content\")"
      ],
      "metadata": {
        "id": "htJ-bU29X9S4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 robust-segmentation/tools/infer.py --adversarial --cfg robust-segmentation/configs/ade20k_segmenter_clean.yaml"
      ],
      "metadata": {
        "id": "-Ghmb3-7YI9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConvNeXt-B"
      ],
      "metadata": {
        "id": "jzCvizQ4XBDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "# в конвнекст\n",
        "url = 'https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224.pth'\n",
        "output = '/content/robust-segmentation/convnext_base_1k_224.pth'  # pretrained\n",
        "\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "ou6U4-7nnFEJ",
        "outputId": "8c572e7b-da9d-40bf-9ebe-6bf3bbab60b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224.pth\n",
            "To: /content/robust-segmentation/convnext_base_1k_224.pth\n",
            "100%|██████████| 354M/354M [00:13<00:00, 26.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/robust-segmentation/convnext_base_1k_224.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# в конвнекст\n",
        "url = 'https://dl.fbaipublicfiles.com/convnext/ade20k/upernet_convnext_base_1k_512x512.pth'\n",
        "output = '/content/robust-segmentation/upernet_convnext_base_1k_512x512.pth'  # fine-tuned\n",
        "\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "pKg3iyJKndFu",
        "outputId": "b9889980-ea49-4311-e609-1599b4d66095"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://dl.fbaipublicfiles.com/convnext/ade20k/upernet_convnext_base_1k_512x512.pth\n",
            "To: /content/robust-segmentation/upernet_convnext_base_1k_512x512.pth\n",
            "100%|██████████| 489M/489M [00:17<00:00, 27.2MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/robust-segmentation/upernet_convnext_base_1k_512x512.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# url = 'https://www.rocq.inria.fr/cluster-willow/rstrudel/segmenter/checkpoints/ade20k/seg_small_mask/checkpoint.pth'\n",
        "# output = '/content/robust-segmentation/clean_384x384.pth'\n",
        "\n",
        "# gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "id": "lCYzQht0ofM0"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "model = torch.load('/content/robust-segmentation/clean_384_384.pth') # с гита\n",
        "\n",
        "# Просмотр ключей в state_dict\n",
        "keys = model['model'].keys()\n",
        "\n",
        "# print(\"Keys в state_dict:\")\n",
        "cls_emb = model['model']['decoder.cls_emb']\n",
        "new_cls_emb = torch.cat((cls_emb, torch.zeros(1, 1, 384)), dim=1)\n",
        "model['model']['decoder.cls_emb'] = new_cls_emb\n",
        "\n",
        "cls_emb1 = model['model']['decoder.mask_norm.weight']\n",
        "new_mask_norm_weight = torch.cat((cls_emb1, torch.zeros(1)), dim=0)\n",
        "model['model']['decoder.mask_norm.weight'] = new_mask_norm_weight\n",
        "\n",
        "cls_emb2 = model['model']['decoder.mask_norm.bias']\n",
        "new_mask_norm_bias = torch.cat((cls_emb2, torch.zeros(1)), dim=0)\n",
        "model['model']['decoder.mask_norm.bias'] = new_mask_norm_bias\n",
        "\n",
        "# model['n_cls'] = 151\n",
        "\n",
        "# for key in model['n_cls'].keys():\n",
        "#   print(key)\n",
        "\n",
        "#checkpoint = torch.load('/content/robust-segmentation/clean_384_384.pth')\n",
        "model_weights = model['model']\n",
        "torch.save(model_weights, '/content/robust-segmentation/check_clean_model_weights!.pth')"
      ],
      "metadata": {
        "id": "wQbCxHkvOX9H"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keys_ = model_weights.keys()\n",
        "# for key in keys_:\n",
        "#     print(key)"
      ],
      "metadata": {
        "id": "FszZbLwN6f0j"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model['model']['decoder.cls_emb'].size())\n",
        "print(model['model']['decoder.mask_norm.weight'].size())\n",
        "print(model['model']['decoder.mask_norm.bias'].size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lkMMc3RVq_Z",
        "outputId": "618f4607-a15f-492f-dee3-6ee00440e786"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 151, 384])\n",
            "torch.Size([151])\n",
            "torch.Size([151])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import ViTImageProcessor, ViTForImageClassification\n",
        "from PIL import Image\n",
        "import requests\n",
        "import torch\n",
        "\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
        "\n",
        "torch.save(model.state_dict(), \"/content/robust-segmentation/model/checkpoint_cl.pth\")"
      ],
      "metadata": {
        "id": "Edaolg3V4aSN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 755 robust-segmentation/runner_infer.sh\n",
        "!./robust-segmentation/runner_infer.sh robust-segmentation/configs/ade20k_segmenter_clean.yaml 0.05"
      ],
      "metadata": {
        "id": "Z8IdzQRdXH79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c54721-04aa-42d7-be5d-0c06ef7b9d1b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "patch_embed proj.weight\n",
            "patch_embed proj.bias\n",
            "blocks 0.norm1.weight\n",
            "blocks 0.norm1.bias\n",
            "blocks 0.norm2.weight\n",
            "blocks 0.norm2.bias\n",
            "blocks 0.attn.qkv.weight\n",
            "blocks 0.attn.qkv.bias\n",
            "blocks 0.attn.proj.weight\n",
            "blocks 0.attn.proj.bias\n",
            "blocks 0.mlp.fc1.weight\n",
            "blocks 0.mlp.fc1.bias\n",
            "blocks 0.mlp.fc2.weight\n",
            "blocks 0.mlp.fc2.bias\n",
            "blocks 1.norm1.weight\n",
            "blocks 1.norm1.bias\n",
            "blocks 1.norm2.weight\n",
            "blocks 1.norm2.bias\n",
            "blocks 1.attn.qkv.weight\n",
            "blocks 1.attn.qkv.bias\n",
            "blocks 1.attn.proj.weight\n",
            "blocks 1.attn.proj.bias\n",
            "blocks 1.mlp.fc1.weight\n",
            "blocks 1.mlp.fc1.bias\n",
            "blocks 1.mlp.fc2.weight\n",
            "blocks 1.mlp.fc2.bias\n",
            "blocks 2.norm1.weight\n",
            "blocks 2.norm1.bias\n",
            "blocks 2.norm2.weight\n",
            "blocks 2.norm2.bias\n",
            "blocks 2.attn.qkv.weight\n",
            "blocks 2.attn.qkv.bias\n",
            "blocks 2.attn.proj.weight\n",
            "blocks 2.attn.proj.bias\n",
            "blocks 2.mlp.fc1.weight\n",
            "blocks 2.mlp.fc1.bias\n",
            "blocks 2.mlp.fc2.weight\n",
            "blocks 2.mlp.fc2.bias\n",
            "blocks 3.norm1.weight\n",
            "blocks 3.norm1.bias\n",
            "blocks 3.norm2.weight\n",
            "blocks 3.norm2.bias\n",
            "blocks 3.attn.qkv.weight\n",
            "blocks 3.attn.qkv.bias\n",
            "blocks 3.attn.proj.weight\n",
            "blocks 3.attn.proj.bias\n",
            "blocks 3.mlp.fc1.weight\n",
            "blocks 3.mlp.fc1.bias\n",
            "blocks 3.mlp.fc2.weight\n",
            "blocks 3.mlp.fc2.bias\n",
            "blocks 4.norm1.weight\n",
            "blocks 4.norm1.bias\n",
            "blocks 4.norm2.weight\n",
            "blocks 4.norm2.bias\n",
            "blocks 4.attn.qkv.weight\n",
            "blocks 4.attn.qkv.bias\n",
            "blocks 4.attn.proj.weight\n",
            "blocks 4.attn.proj.bias\n",
            "blocks 4.mlp.fc1.weight\n",
            "blocks 4.mlp.fc1.bias\n",
            "blocks 4.mlp.fc2.weight\n",
            "blocks 4.mlp.fc2.bias\n",
            "blocks 5.norm1.weight\n",
            "blocks 5.norm1.bias\n",
            "blocks 5.norm2.weight\n",
            "blocks 5.norm2.bias\n",
            "blocks 5.attn.qkv.weight\n",
            "blocks 5.attn.qkv.bias\n",
            "blocks 5.attn.proj.weight\n",
            "blocks 5.attn.proj.bias\n",
            "blocks 5.mlp.fc1.weight\n",
            "blocks 5.mlp.fc1.bias\n",
            "blocks 5.mlp.fc2.weight\n",
            "blocks 5.mlp.fc2.bias\n",
            "blocks 6.norm1.weight\n",
            "blocks 6.norm1.bias\n",
            "blocks 6.norm2.weight\n",
            "blocks 6.norm2.bias\n",
            "blocks 6.attn.qkv.weight\n",
            "blocks 6.attn.qkv.bias\n",
            "blocks 6.attn.proj.weight\n",
            "blocks 6.attn.proj.bias\n",
            "blocks 6.mlp.fc1.weight\n",
            "blocks 6.mlp.fc1.bias\n",
            "blocks 6.mlp.fc2.weight\n",
            "blocks 6.mlp.fc2.bias\n",
            "blocks 7.norm1.weight\n",
            "blocks 7.norm1.bias\n",
            "blocks 7.norm2.weight\n",
            "blocks 7.norm2.bias\n",
            "blocks 7.attn.qkv.weight\n",
            "blocks 7.attn.qkv.bias\n",
            "blocks 7.attn.proj.weight\n",
            "blocks 7.attn.proj.bias\n",
            "blocks 7.mlp.fc1.weight\n",
            "blocks 7.mlp.fc1.bias\n",
            "blocks 7.mlp.fc2.weight\n",
            "blocks 7.mlp.fc2.bias\n",
            "blocks 8.norm1.weight\n",
            "blocks 8.norm1.bias\n",
            "blocks 8.norm2.weight\n",
            "blocks 8.norm2.bias\n",
            "blocks 8.attn.qkv.weight\n",
            "blocks 8.attn.qkv.bias\n",
            "blocks 8.attn.proj.weight\n",
            "blocks 8.attn.proj.bias\n",
            "blocks 8.mlp.fc1.weight\n",
            "blocks 8.mlp.fc1.bias\n",
            "blocks 8.mlp.fc2.weight\n",
            "blocks 8.mlp.fc2.bias\n",
            "blocks 9.norm1.weight\n",
            "blocks 9.norm1.bias\n",
            "blocks 9.norm2.weight\n",
            "blocks 9.norm2.bias\n",
            "blocks 9.attn.qkv.weight\n",
            "blocks 9.attn.qkv.bias\n",
            "blocks 9.attn.proj.weight\n",
            "blocks 9.attn.proj.bias\n",
            "blocks 9.mlp.fc1.weight\n",
            "blocks 9.mlp.fc1.bias\n",
            "blocks 9.mlp.fc2.weight\n",
            "blocks 9.mlp.fc2.bias\n",
            "blocks 10.norm1.weight\n",
            "blocks 10.norm1.bias\n",
            "blocks 10.norm2.weight\n",
            "blocks 10.norm2.bias\n",
            "blocks 10.attn.qkv.weight\n",
            "blocks 10.attn.qkv.bias\n",
            "blocks 10.attn.proj.weight\n",
            "blocks 10.attn.proj.bias\n",
            "blocks 10.mlp.fc1.weight\n",
            "blocks 10.mlp.fc1.bias\n",
            "blocks 10.mlp.fc2.weight\n",
            "blocks 10.mlp.fc2.bias\n",
            "blocks 11.norm1.weight\n",
            "blocks 11.norm1.bias\n",
            "blocks 11.norm2.weight\n",
            "blocks 11.norm2.bias\n",
            "blocks 11.attn.qkv.weight\n",
            "blocks 11.attn.qkv.bias\n",
            "blocks 11.attn.proj.weight\n",
            "blocks 11.attn.proj.bias\n",
            "blocks 11.mlp.fc1.weight\n",
            "blocks 11.mlp.fc1.bias\n",
            "blocks 11.mlp.fc2.weight\n",
            "blocks 11.mlp.fc2.bias\n",
            "norm weight\n",
            "norm bias\n",
            "head weight\n",
            "head bias\n",
            "dict_keys(['encoder.cls_token', 'encoder.pos_embed', 'encoder.patch_embed.proj.weight', 'encoder.patch_embed.proj.bias', 'encoder.blocks.0.norm1.weight', 'encoder.blocks.0.norm1.bias', 'encoder.blocks.0.norm2.weight', 'encoder.blocks.0.norm2.bias', 'encoder.blocks.0.attn.qkv.weight', 'encoder.blocks.0.attn.qkv.bias', 'encoder.blocks.0.attn.proj.weight', 'encoder.blocks.0.attn.proj.bias', 'encoder.blocks.0.mlp.fc1.weight', 'encoder.blocks.0.mlp.fc1.bias', 'encoder.blocks.0.mlp.fc2.weight', 'encoder.blocks.0.mlp.fc2.bias', 'encoder.blocks.1.norm1.weight', 'encoder.blocks.1.norm1.bias', 'encoder.blocks.1.norm2.weight', 'encoder.blocks.1.norm2.bias', 'encoder.blocks.1.attn.qkv.weight', 'encoder.blocks.1.attn.qkv.bias', 'encoder.blocks.1.attn.proj.weight', 'encoder.blocks.1.attn.proj.bias', 'encoder.blocks.1.mlp.fc1.weight', 'encoder.blocks.1.mlp.fc1.bias', 'encoder.blocks.1.mlp.fc2.weight', 'encoder.blocks.1.mlp.fc2.bias', 'encoder.blocks.2.norm1.weight', 'encoder.blocks.2.norm1.bias', 'encoder.blocks.2.norm2.weight', 'encoder.blocks.2.norm2.bias', 'encoder.blocks.2.attn.qkv.weight', 'encoder.blocks.2.attn.qkv.bias', 'encoder.blocks.2.attn.proj.weight', 'encoder.blocks.2.attn.proj.bias', 'encoder.blocks.2.mlp.fc1.weight', 'encoder.blocks.2.mlp.fc1.bias', 'encoder.blocks.2.mlp.fc2.weight', 'encoder.blocks.2.mlp.fc2.bias', 'encoder.blocks.3.norm1.weight', 'encoder.blocks.3.norm1.bias', 'encoder.blocks.3.norm2.weight', 'encoder.blocks.3.norm2.bias', 'encoder.blocks.3.attn.qkv.weight', 'encoder.blocks.3.attn.qkv.bias', 'encoder.blocks.3.attn.proj.weight', 'encoder.blocks.3.attn.proj.bias', 'encoder.blocks.3.mlp.fc1.weight', 'encoder.blocks.3.mlp.fc1.bias', 'encoder.blocks.3.mlp.fc2.weight', 'encoder.blocks.3.mlp.fc2.bias', 'encoder.blocks.4.norm1.weight', 'encoder.blocks.4.norm1.bias', 'encoder.blocks.4.norm2.weight', 'encoder.blocks.4.norm2.bias', 'encoder.blocks.4.attn.qkv.weight', 'encoder.blocks.4.attn.qkv.bias', 'encoder.blocks.4.attn.proj.weight', 'encoder.blocks.4.attn.proj.bias', 'encoder.blocks.4.mlp.fc1.weight', 'encoder.blocks.4.mlp.fc1.bias', 'encoder.blocks.4.mlp.fc2.weight', 'encoder.blocks.4.mlp.fc2.bias', 'encoder.blocks.5.norm1.weight', 'encoder.blocks.5.norm1.bias', 'encoder.blocks.5.norm2.weight', 'encoder.blocks.5.norm2.bias', 'encoder.blocks.5.attn.qkv.weight', 'encoder.blocks.5.attn.qkv.bias', 'encoder.blocks.5.attn.proj.weight', 'encoder.blocks.5.attn.proj.bias', 'encoder.blocks.5.mlp.fc1.weight', 'encoder.blocks.5.mlp.fc1.bias', 'encoder.blocks.5.mlp.fc2.weight', 'encoder.blocks.5.mlp.fc2.bias', 'encoder.blocks.6.norm1.weight', 'encoder.blocks.6.norm1.bias', 'encoder.blocks.6.norm2.weight', 'encoder.blocks.6.norm2.bias', 'encoder.blocks.6.attn.qkv.weight', 'encoder.blocks.6.attn.qkv.bias', 'encoder.blocks.6.attn.proj.weight', 'encoder.blocks.6.attn.proj.bias', 'encoder.blocks.6.mlp.fc1.weight', 'encoder.blocks.6.mlp.fc1.bias', 'encoder.blocks.6.mlp.fc2.weight', 'encoder.blocks.6.mlp.fc2.bias', 'encoder.blocks.7.norm1.weight', 'encoder.blocks.7.norm1.bias', 'encoder.blocks.7.norm2.weight', 'encoder.blocks.7.norm2.bias', 'encoder.blocks.7.attn.qkv.weight', 'encoder.blocks.7.attn.qkv.bias', 'encoder.blocks.7.attn.proj.weight', 'encoder.blocks.7.attn.proj.bias', 'encoder.blocks.7.mlp.fc1.weight', 'encoder.blocks.7.mlp.fc1.bias', 'encoder.blocks.7.mlp.fc2.weight', 'encoder.blocks.7.mlp.fc2.bias', 'encoder.blocks.8.norm1.weight', 'encoder.blocks.8.norm1.bias', 'encoder.blocks.8.norm2.weight', 'encoder.blocks.8.norm2.bias', 'encoder.blocks.8.attn.qkv.weight', 'encoder.blocks.8.attn.qkv.bias', 'encoder.blocks.8.attn.proj.weight', 'encoder.blocks.8.attn.proj.bias', 'encoder.blocks.8.mlp.fc1.weight', 'encoder.blocks.8.mlp.fc1.bias', 'encoder.blocks.8.mlp.fc2.weight', 'encoder.blocks.8.mlp.fc2.bias', 'encoder.blocks.9.norm1.weight', 'encoder.blocks.9.norm1.bias', 'encoder.blocks.9.norm2.weight', 'encoder.blocks.9.norm2.bias', 'encoder.blocks.9.attn.qkv.weight', 'encoder.blocks.9.attn.qkv.bias', 'encoder.blocks.9.attn.proj.weight', 'encoder.blocks.9.attn.proj.bias', 'encoder.blocks.9.mlp.fc1.weight', 'encoder.blocks.9.mlp.fc1.bias', 'encoder.blocks.9.mlp.fc2.weight', 'encoder.blocks.9.mlp.fc2.bias', 'encoder.blocks.10.norm1.weight', 'encoder.blocks.10.norm1.bias', 'encoder.blocks.10.norm2.weight', 'encoder.blocks.10.norm2.bias', 'encoder.blocks.10.attn.qkv.weight', 'encoder.blocks.10.attn.qkv.bias', 'encoder.blocks.10.attn.proj.weight', 'encoder.blocks.10.attn.proj.bias', 'encoder.blocks.10.mlp.fc1.weight', 'encoder.blocks.10.mlp.fc1.bias', 'encoder.blocks.10.mlp.fc2.weight', 'encoder.blocks.10.mlp.fc2.bias', 'encoder.blocks.11.norm1.weight', 'encoder.blocks.11.norm1.bias', 'encoder.blocks.11.norm2.weight', 'encoder.blocks.11.norm2.bias', 'encoder.blocks.11.attn.qkv.weight', 'encoder.blocks.11.attn.qkv.bias', 'encoder.blocks.11.attn.proj.weight', 'encoder.blocks.11.attn.proj.bias', 'encoder.blocks.11.mlp.fc1.weight', 'encoder.blocks.11.mlp.fc1.bias', 'encoder.blocks.11.mlp.fc2.weight', 'encoder.blocks.11.mlp.fc2.bias', 'encoder.norm.weight', 'encoder.norm.bias', 'encoder.head.weight', 'encoder.head.bias', 'decoder.cls_emb', 'decoder.proj_patch', 'decoder.proj_classes', 'decoder.blocks.0.norm1.weight', 'decoder.blocks.0.norm1.bias', 'decoder.blocks.0.norm2.weight', 'decoder.blocks.0.norm2.bias', 'decoder.blocks.0.attn.qkv.weight', 'decoder.blocks.0.attn.qkv.bias', 'decoder.blocks.0.attn.proj.weight', 'decoder.blocks.0.attn.proj.bias', 'decoder.blocks.0.mlp.fc1.weight', 'decoder.blocks.0.mlp.fc1.bias', 'decoder.blocks.0.mlp.fc2.weight', 'decoder.blocks.0.mlp.fc2.bias', 'decoder.blocks.1.norm1.weight', 'decoder.blocks.1.norm1.bias', 'decoder.blocks.1.norm2.weight', 'decoder.blocks.1.norm2.bias', 'decoder.blocks.1.attn.qkv.weight', 'decoder.blocks.1.attn.qkv.bias', 'decoder.blocks.1.attn.proj.weight', 'decoder.blocks.1.attn.proj.bias', 'decoder.blocks.1.mlp.fc1.weight', 'decoder.blocks.1.mlp.fc1.bias', 'decoder.blocks.1.mlp.fc2.weight', 'decoder.blocks.1.mlp.fc2.bias', 'decoder.proj_dec.weight', 'decoder.proj_dec.bias', 'decoder.decoder_norm.weight', 'decoder.decoder_norm.bias', 'decoder.mask_norm.weight', 'decoder.mask_norm.bias'])\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/robust-segmentation/tools/infer.py\", line 359, in <module>\n",
            "    val_data_loader = get_data(dataset_cfg, test_cfg)\n",
            "  File \"/content/robust-segmentation/tools/infer.py\", line 286, in get_data\n",
            "    val_data = get_segmentation_dataset(test_cfg['NAME'],\n",
            "  File \"/content/robust-segmentation/tools/semseg/datasets/__init__.py\", line 31, in get_segmentation_dataset\n",
            "    return datasets[name.lower()](**kwargs)\n",
            "  File \"/content/robust-segmentation/tools/semseg/datasets/ade.py\", line 50, in __init__\n",
            "    assert os.path.exists(root), \"Please setup the dataset using ../datasets/ade20k.py\"\n",
            "AssertionError: Please setup the dataset using ../datasets/ade20k.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "# в конвнекст\n",
        "url = 'https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224.pth'\n",
        "output = '/content/robust-segmentation/convnext_base_1k_224.pth'  # pretrained\n",
        "\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "z9lrBCRk5HDe",
        "outputId": "3fe34666-c8b8-4e4a-d23b-9afe7ff6a53b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://dl.fbaipublicfiles.com/convnext/convnext_base_1k_224.pth\n",
            "To: /content/robust-segmentation/convnext_base_1k_224.pth\n",
            "100%|██████████| 354M/354M [00:10<00:00, 33.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/robust-segmentation/convnext_base_1k_224.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# в конвнекст\n",
        "url = 'https://dl.fbaipublicfiles.com/convnext/ade20k/upernet_convnext_base_1k_512x512.pth'\n",
        "output = '/content/robust-segmentation/upernet_convnext_base_1k_512x512.pth'  # fine-tuned\n",
        "\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "WA0lm7KK6D-V",
        "outputId": "dfba9176-6e53-4974-f8f5-5c862905adf1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://dl.fbaipublicfiles.com/convnext/ade20k/upernet_convnext_base_1k_512x512.pth\n",
            "To: /content/robust-segmentation/upernet_convnext_base_1k_512x512.pth\n",
            "100%|██████████| 489M/489M [00:11<00:00, 41.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/robust-segmentation/upernet_convnext_base_1k_512x512.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}